{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StyleGAN2_ADA generator.ipynb","provenance":[{"file_id":"1i3dywb5pOwAxdhYv9O-pXwc2mqivmofJ","timestamp":1605871510447},{"file_id":"https://github.com/dvschultz/ai/blob/master/flesh_digressions.ipynb","timestamp":1605672917355}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AziEPhUfHnfP"},"source":["# Generate stuff using StyleGAN2-ADA model\n","\n","This colab is to generate stuff using a StyleGAN2_ADA model\n","\n","Using this (https://github.com/dvschultz/stylegan2-ada/)"]},{"cell_type":"markdown","metadata":{"id":"AoJPgA3pXj5c"},"source":["#Setup"]},{"cell_type":"code","metadata":{"id":"gORlgsBhsgjm"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vvce3RFakdjx"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXxfhVcFrfJk"},"source":["# Clone the StyleGAN2-ADA & install opensimplex\n","%cd ~\n","%cd /content\n","!git clone https://github.com/dvschultz/stylegan2-ada/\n","\n","!pip install opensimplex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAp0Tt7yr6bE"},"source":["# Download the model\n","pkl = !gdown --id 11BrC4tjlkns_mZtVO6pblDd-p2xmypZ5 -O \"/content/model_name.pkl\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y85_aIs9HHfE"},"source":["# Set the model\n","# can also use the path directly\n","pkl = \"/content/model_name.pkl\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cNVmp4D6HQQd"},"source":["# Generate stuff"]},{"cell_type":"code","metadata":{"id":"pZMZojm5a49l"},"source":["!python /content/stylegan2-ada/generate.py --help"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4hrW_VhSHViq"},"source":["# Generate fakes(images) (Latent space)\n","# --seeds         seed valuse are pictures\n","# --trunc         between 0-1 (1 is default)\n","\n","!python /content/stylegan2-ada/generate.py generate-images --network=$pkl --trunc=1 --seeds=0-20 --outdir=\"/content/out/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"InymIv6qJVDx"},"source":["# Generate Truncation traversal\n","# --seed            should be a single value\n","# --start           starting truncation value\n","# --stop            Stoping truncation value (must be more the start value)\n","# --increment       smaller the value, longer the video\n","\n","!python /content/stylegan2-ada/generate.py truncation-traversal --network=$pkl --seed=1 --start=-2.0 --stop=1.0 --increment=0.05 --fps=24 --outdir=\"/content/tt/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8EZuTTaOUmw"},"source":["# Linear interpolation\n","# --walk-type=\"line-z\" or --walk-type=\"line-w\"\n","# --seeds         seed valuse are pictures\n","\n","!python /content/stylegan2-ada/generate.py generate-latent-walk --network=$pkl --walk-type=\"line-z\" --seeds=1,2,3,4,1 --outdir=\"/content/latent/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZGzKulxPkoH"},"source":["# Noise loop interpolation (like above but smoother)\n","# --walk-type=\"line-z\" (only)\n","# --start_seed         starting value\n","# --diameter           length of the video\n","\n","!python /content/stylegan2-ada/generate.py generate-latent-walk --network=$pkl --walk-type=\"noiseloop\" --start_seed=1 --diameter=2.0 --outdir=\"/content/noiseloop/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaCPOeXRawrb"},"source":["# Near neighbours\n","# --seeds         seed valuse are pictures\n","# --diameter      how far it will look for the neighbours (0-1) (0.0000001 is super close, 0.5 is very far)\n","# --num_samples   how many samples to produce\n","# --save_vector   this will save the vector in .npy format\n","\n","!python /content/stylegan2-ada/generate.py generate-neighbors --network=$pkl --seeds=1 --outdir=\"/content/neighbours/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9vAZjDdgdOuh"},"source":["# Lerp video\n","# --seeds             seed valuse are pictures\n","# --grid_w            Number of columns\n","# --grid_h            Number of rows\n","# --truncation_psi    Default value is 1\n","# --slowdown          Slowdown of the video (power of 2)\n","# --duration_sec      Duration of the video in seconds\n","\n","\n","!python /content/stylegan2-ada/generate.py lerp-video --network=$pkl --seeds=1 --outdir=\"/content/lerp/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nt9IAnWbsWj_"},"source":["# Flesh digressions\n","#   --pkl:                point this to your pkl model file\n","#   --psi:                truncation value\n","#   --radius_large:       how large of a loop the constant layer should be \n","#   --radius_small:       how large of a loop the latent space layer should be \n","#   --step1: increment    step for the constant layer \n","#   --step2: increment    step for the latent space layer \n","#   --video_length:       length of video in circular interpolation (ex. default is 1.0, step2 is 0.0025, so video length is 400 frames)\n","\n","!python /content/stylegan2-ada/aydao_flesh_digressions.py --pkl $pkl --psi=0.5 --step1=0.001 --step2=0.0025 --video_length=1.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o62Z8bFSRtzM"},"source":["# Style mixing\n","#  --rows ROW_SEEDS         Random seeds to use for image rows\n","#  --cols COL_SEEDS         Random seeds to use for image columns\n","#  --styles COL_STYLES      Style layer range (default: 0-6)\n","#  --trunc TRUNCATION_PSI   Truncation psi (default: 0.5)\n","\n","!python /content/stylegan2-ada/style_mixing.py --network=$pkl --rows=10,25,46,80 --cols=12,19,38,67 --outdir=\"/content/stylemix/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JAFHGZa3ZRGJ"},"source":["# Projection\n","#  --seed           Select a random seed\n","#  --target         Image to project with\n","\n","!python /content/stylegan2-ada/projector.py --network=$pkl --target=\"/content/face.jpg\" --outdir=\"/content/projector/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1j6crvL4LdSD"},"source":["#Unility code"]},{"cell_type":"code","metadata":{"id":"DyVhKUQ7GA6b"},"source":["# Zip folder to download\n","!zip -r /content/tt1.zip /content/stylegan2-ada/tt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJylbwz2vn0i"},"source":["# Resize and delete the video\n","\n","import moviepy.editor as mp\n","import os\n","\n","name = \"/content/stylegan2-ada/circular-22-11-2020-08-03-40-PM\"\n","formatEx = \".mp4\"\n","\n","clip = mp.VideoFileClip(name + formatEx)\n","clip_resized = clip.resize(height=500)\n","clip_resized.write_videofile(name + \"_r\" + formatEx)\n","\n","# os.remove(name + formatEx) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nS5ivfJHLoS2"},"source":["# if you want to delete a directory\n","\n","import shutil\n","\n","shutil.rmtree('/content/out')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"llB2kYS8LrdG"},"source":["# if you want to delete a file\n","\n","import os\n","os.remove(\"/content/expressions/.DS_Store\") "],"execution_count":null,"outputs":[]}]}